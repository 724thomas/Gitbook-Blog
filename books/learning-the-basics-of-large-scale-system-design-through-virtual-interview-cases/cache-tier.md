---
description: 캐시 계층
---

# Cache tier

성능 개선 및 데이터베이스의 부하를 줄이기 위해 웹서버와 데이터베이스 사이에 캐시서버를 둔다.



* 캐시는 어떤 상황에 바람직한가?
  * 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어날때 고려한다.
* 어떤 데이터를 캐시에 두어야 하는가?
  * 캐시는 데이터를 휘발성 메모리에 두므로, 영구적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.
  * 캐시 서버가 재시작되면 캐시 내 모든 데이터들은 날아간다.
* 캐시에 부관된 데이터는 어떻게 만료 되는가?
  * 만료 정책을 마련해야한다.
  * 만료 기한이 너무 짧으면 데이터베이스를 자주 읽게 된다.
  * 만료 기한이 너무 길면 원본과 차이가 날 가능성이 높아진다.
* 일관성은 어떻게 유지되는가?
  * 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되야 한다.
* 장애에는 어떻게 대처할 것인가?
  * 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure)이 되어버릴 가능성이 있다.
  * SPOF를 피하기 위해서는 캐시 서버를 분산시켜야 한다.
* 캐시 메모리는 얼마나 크게 잡을 건가?
  * 캐시 메모리가 작을때
    * 동기화 관리가 상대적으로 더 간단하다.
    * 잦은 캐시미스로캐시의 성능이 떨어진다.
  * 캐시 메모리가 클때
    * 더 많은 데이터를 저장할 수 있기때문에 데이터베이스의 접근을 줄이고 응답시간을 단축시킨다.
    * 사용하지않는 데이터를 캐싱할 경우 메모리 자원이 낭비된다.
    * 동기화가 복잡해지고 오버헤드가 증가할 수 있다.



캐시 정책:

* LRU (Least Recently Used)
  * 가장 오래동안 사용되지 않은 항목을 캐시에서 제거한다.
  * 최근에 사용된 데이터가 미래에도 사용될 가능성이 높다는 가정.
  * 구현이 간단하다.
* FIFO (First In, First Out)
  * 캐시에 가장 먼저 들어온 데이터를 제거한다.
  * 최근  또는 자주 사용되는 데이터가 제거될 수 있다.
* Random Replacement
  * 임의의 항목을 제거 한다.
  * 구현이 매우 간단하다.
* Adaptive Replacement Cache (ARC)
  * 최근에 사요요된 항목과 자주 사용된 항목의 균형을 유지한다.
  * LRU와 LFU의 결합 상태
* MRU (Most Recently Used)
  * 가장 최근에 사용된 항목을 캐시에서 제거한다.
* 2Q
  * LRU의 변형으로 두개의 큐를 사용해서 캐시를 관리한다.
  * 하나의 큐는 최근에 접근된 데이터를 관리하고, 다른 하나는 자주 접근되는 데이터를 관리한다.
